{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Reviews Sentiment Predictor\n",
    "### Developer - Ashima Munjal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dependencies.\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Natural Language Processing Libraries.\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Machine Learning Libraries.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Reviews Data.\n",
    "#### The dataset for this project was taken from [Kaggle](https://www.kaggle.com/yelp-dataset/yelp-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Super simple place but amazing nonetheless. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>VR6GpWIda3SfvPC-lg9H3w</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Small unassuming place that changes their menu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>CKC0-MOWMqoeWf6s-szl8g</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>ACFtxLv8pGrrxMm6EgjreA</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Love coming here. Yes the place always needs t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L_9BTb55X0GDtThi6GlZ6w</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>s2I_Ni76bjJNK9yG60iD-Q</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Had their chocolate almond croissant and it wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  vkVSCC7xljjrAI4UGfnKEQ  bv2nCi5Qv5vroFiqKGopiw  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1  n6QzIUObkYshz4dz2QRJTw  bv2nCi5Qv5vroFiqKGopiw  VR6GpWIda3SfvPC-lg9H3w   \n",
       "2  MV3CcKScW05u5LVfF6ok0g  bv2nCi5Qv5vroFiqKGopiw  CKC0-MOWMqoeWf6s-szl8g   \n",
       "3  IXvOzsEMYtiJI0CARmj77Q  bv2nCi5Qv5vroFiqKGopiw  ACFtxLv8pGrrxMm6EgjreA   \n",
       "4  L_9BTb55X0GDtThi6GlZ6w  bv2nCi5Qv5vroFiqKGopiw  s2I_Ni76bjJNK9yG60iD-Q   \n",
       "\n",
       "   stars        date                                               text  \\\n",
       "0      5  2016-05-28  Super simple place but amazing nonetheless. It...   \n",
       "1      5  2016-05-28  Small unassuming place that changes their menu...   \n",
       "2      5  2016-05-28  Lester's is located in a beautiful neighborhoo...   \n",
       "3      4  2016-05-28  Love coming here. Yes the place always needs t...   \n",
       "4      4  2016-05-28  Had their chocolate almond croissant and it wa...   \n",
       "\n",
       "   useful  funny  cool  \n",
       "0       0      0     0  \n",
       "1       0      0     0  \n",
       "2       0      0     0  \n",
       "3       0      0     0  \n",
       "4       0      0     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strt_time = time.time()\n",
    "data = pd.read_csv(\"yelp_data\\\\yelp_review.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting a balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5 = data[data.stars.isin([5])]\n",
    "data_5 = data_5.head(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4 = data[data.stars.isin([4])]\n",
    "data_4 = data_4.head(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3 = data[data.stars.isin([3])]\n",
    "data_3 = data_3.head(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = data[data.stars.isin([2])]\n",
    "data_2 = data_2.head(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data[data.stars.isin([1])]\n",
    "data_1 = data_1.head(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [data_5, data_4, data_3, data_2, data_1]\n",
    "final_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the required columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (100000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Super simple place but amazing nonetheless. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Small unassuming place that changes their menu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Cycle Pub Las Vegas was a blast! Got a groupon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Love this place!\\n\\nPeggy is great with dogs a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text\n",
       "0      5  Super simple place but amazing nonetheless. It...\n",
       "1      5  Small unassuming place that changes their menu...\n",
       "2      5  Lester's is located in a beautiful neighborhoo...\n",
       "5      5  Cycle Pub Las Vegas was a blast! Got a groupon...\n",
       "9      5  Love this place!\\n\\nPeggy is great with dogs a..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = final_df[['stars', 'text']]\n",
    "print(\"Data Shape:\", data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Text Processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "def clean_text(txt):\n",
    "    \n",
    "    # Compile Regex Information.\n",
    "    # URL Regex.\n",
    "    url_reg = re.compile(r'https?://(www.)?\\w+\\.\\w+(/\\w+)*/?')\n",
    "    \n",
    "    # Regex to treat \"@mentions\".\n",
    "    mention_reg = re.compile(r'@(\\w+)')\n",
    "\n",
    "    # Remove hyperlinks.\n",
    "    txt = url_reg.sub(' ', txt)\n",
    "    \n",
    "    # Remove text containing \"@mentions\".\n",
    "    txt = mention_reg.sub(' ', txt)\n",
    "\n",
    "    # Removing punctuations.\n",
    "    txt = re.sub('[^a-zA-Z]', ' ', txt)\n",
    "\n",
    "    # Convert to lower case.\n",
    "    txt = txt.lower()\n",
    "\n",
    "    # Remove tags.\n",
    "    txt = re.sub(\"&lt;/?.*?&gt;\", \" &lt;&gt; \", txt)\n",
    "\n",
    "    # Remove special characters and digits.\n",
    "    txt = re.sub(\"(\\\\d|\\\\W)+\", \" \", txt)\n",
    "\n",
    "    # Convert to list from string by splitting on \"space\" character.\n",
    "    txt = txt.split(\" \")\n",
    "\n",
    "    # Remove empty strings.\n",
    "    txt = [wrd for wrd in txt if wrd != \"\"]\n",
    "    \n",
    "    # Form sentences from words.\n",
    "    txt = \" \".join(txt)\n",
    "\n",
    "    return txt\n",
    "\n",
    "# Applying Text Processing to data.\n",
    "data_df[\"Cleaned_Text\"] = data_df[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = data_df[\"Cleaned_Text\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing Training Data File.\n",
    "file = open('training_file.txt','w')\n",
    "for ele in data_file:\n",
    "    try:\n",
    "        file.write(str(ele) + '\\n')\n",
    "    except:\n",
    "        pass\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = data_df[\"stars\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing Training Label File.\n",
    "file = open('training_label_file.txt','w')\n",
    "for ele in data_label:\n",
    "    try:\n",
    "        file.write(str(ele) + '\\n')\n",
    "    except:\n",
    "        pass\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the stored training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (100000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>super simple place but amazing nonetheless it ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small unassuming place that changes their menu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lester s is located in a beautiful neighborhoo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cycle pub las vegas was a blast got a groupon ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love this place peggy is great with dogs and d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  super simple place but amazing nonetheless it ...      5\n",
       "1  small unassuming place that changes their menu...      5\n",
       "2  lester s is located in a beautiful neighborhoo...      5\n",
       "3  cycle pub las vegas was a blast got a groupon ...      5\n",
       "4  love this place peggy is great with dogs and d...      5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading training data.\n",
    "training_file = open(\"training_file.txt\",\"r\") \n",
    "data_train = []\n",
    "for line in training_file.readlines():\n",
    "    data_train.append(line)\n",
    "\n",
    "# Loading labels.\n",
    "training_labl_file = open(\"training_label_file.txt\",\"r\") \n",
    "data_label = []\n",
    "for line in training_labl_file.readlines():\n",
    "    data_label.append(int(line.strip(\"\\n\")))\n",
    "\n",
    "# Creating dataframe.\n",
    "data_df = pd.DataFrame({\"text\":data_train,\n",
    "                        \"stars\":data_label})\n",
    "print(\"Training Data Shape:\", data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering Stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(txt):\n",
    "   \n",
    "    # Stop Words list from \"NLTK\" library.\n",
    "    stop_wrds = [\"out\", \"we\", \"was\", \"how\", \"myself\", \"for\", \"they\", \"about\", \"hasn't\",\n",
    "                 \"then\", \"both\", \"so\", \"re\", \"don\", \"m\", \"as\", \"any\", \"mightn\", \"after\",\n",
    "                 \"you\", \"wouldn\", \"why\", \"been\", \"where\", \"by\", \"isn't\",\n",
    "                 \"yourself\", \"wasn\", \"a\", \"haven't\", \"did\", \"hadn't\", \"their\", \"hasn\",\n",
    "                 \"doing\", \"be\", \"further\", \"ours\", \"now\", \"am\", \"her\", \"you'll\",\n",
    "                 \"yourselves\", \"that\", \"my\", \"what\", \"to\", \"d\", \"not\", \"won't\", \"couldn't\",\n",
    "                 \"own\", \"there\", \"this\", \"each\", \"all\", \"haven\", \"more\", \"me\", \"ve\", \"weren\",\n",
    "                 \"which\", \"himself\", \"nor\", \"other\", \"shouldn't\", \"who\", \"should've\", \"same\",\n",
    "                 \"at\", \"such\", \"t\", \"up\", \"than\", \"can\", \"you've\", \"too\", \"these\", \"while\",\n",
    "                 \"wasn't\", \"ourselves\", \"before\", \"i\", \"he\", \"didn't\", \"our\", \"its\", \"but\", \"with\",\n",
    "                 \"wouldn't\", \"those\", \"because\", \"the\", \"y\", \"shouldn\", \"it\", \"mustn\", \"hers\", \"just\",\n",
    "                 \"doesn\", \"ain\", \"between\", \"over\", \"had\", \"aren\", \"mightn't\", \"does\", \"have\", \"and\", \n",
    "                 \"or\", \"some\", \"mustn't\", \"only\", \"won\", \"when\", \"needn\", \"below\", \"in\", \"if\",\n",
    "                 \"theirs\", \"needn't\", \"aren't\", \"isn\", \"again\", \"his\", \"whom\", \"ll\", \"hadn\",\n",
    "                 \"above\", \"should\", \"itself\", \"themselves\", \"until\", \"are\", \"she\", \"no\", \"from\",\n",
    "                 \"into\", \"will\", \"your\", \"few\",\"here\", \"is\", \"s\", \"don't\", \"shan't\", \"during\", \"she's\",\n",
    "                 \"herself\", \"of\", \"has\", \"down\", \"were\", \"once\", \"ma\", \"having\", \"them\", \"under\", \"him\",\n",
    "                 \"shan\", \"couldn\", \"do\", \"on\", \"an\", \"you\\'d\", \"yours\", \"being\", \"off\", \"o\", \"that'll\",\n",
    "                 \"very\", \"weren't\", \"didn\", \"through\", \"you're\", \"most\", \"against\", \"it's\", \"doesn't\"]\n",
    "\n",
    "    # Convert to list from string by splitting on \"space\" character.\n",
    "    txt = txt.split(\" \")\n",
    "\n",
    "    # Words describing relationships. \n",
    "    rl_wrds = ['guy','spokesman','chairman',\"men's\",'men','him',\"he's\",'his',\n",
    "               'boy','boyfriend','boyfriends','boys','brother','brothers','dad',\n",
    "               'dads','dude','father','fathers','fiance','gentleman','gentlemen',\n",
    "               'god','grandfather','grandpa','grandson','groom','he','himself',\n",
    "               'husband','husbands','king','male','man','mr','nephew','nephews',\n",
    "               'priest','prince','son','sons','uncle','uncles','waiter','widower',\n",
    "               'widowers', 'heroine','spokeswoman','chairwoman',\"women's\",'actress',\n",
    "               \"she's\",'her','aunt','aunts','bride','daughter','daughters','female',\n",
    "               'fiancee','girl','girlfriend','girlfriends','girls','goddess',\n",
    "               'granddaughter','grandma','grandmother','herself','ladies','lady',\n",
    "               'lady','mom','moms','mother','mothers','mrs','ms','niece','nieces',\n",
    "               'priestess','princess','queens','she','sister','sisters','waitress',\n",
    "               'widow','widows','wife','wives','woman', 'women']\n",
    "\n",
    "    # Words representing utterances.\n",
    "    utterance_wrds = [\"um\", \"huh\"]\n",
    "\n",
    "    # Complete Stop Word List.\n",
    "    stop_wrds += rl_wrds + utterance_wrds\n",
    "\n",
    "    # Removing stop words.\n",
    "    txt = [word for word in txt if word not in stop_wrds]\n",
    "\n",
    "    # Form sentences from words.\n",
    "    txt = \" \".join(txt)\n",
    "\n",
    "    return txt\n",
    "\n",
    "# Removing stop words.\n",
    "data_df[\"Filtered_Text\"] = data_df[\"text\"].apply(filter_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(txt):\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    # Convert to list from string by splitting on \"space\" character.\n",
    "    txt = txt.split(\" \")\n",
    "    stemmed = []\n",
    "    for ele in txt:\n",
    "        stemmed += [ps.stem(ele)]\n",
    "\n",
    "    # Form sentences from words.\n",
    "    txt = \" \".join(stemmed)\n",
    "    return txt\n",
    "\n",
    "# Apply stemming to identify root words.\n",
    "data_df[\"Stemmed_Text\"] = data_df[\"Filtered_Text\"].apply(stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing Sentiment Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_scr(txt):\n",
    "    \n",
    "    scr = TextBlob(txt).sentiment.polarity\n",
    "\n",
    "    return scr\n",
    "\n",
    "# Get Sentiment Score.\n",
    "data_df[\"Sentiment_Score\"] = data_df[\"Stemmed_Text\"].apply(sentiment_scr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Weighted Score using Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"Score\"] = data_df[\"Sentiment_Score\"] * data_df[\"stars\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labeling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_threshold(scr):\n",
    "    if (scr >= 0.5):\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    return label\n",
    "\n",
    "# Labeling based on threshold.\n",
    "data_df[\"Label\"] = data_df[\"Score\"].apply(label_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data for ML Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df = data_df[[\"Stemmed_Text\", \"Label\"]]\n",
    "split = np.random.rand(len(ml_df)) < 0.8\n",
    "train = ml_df[split]\n",
    "test = ml_df[~split]\n",
    "clean_train_corpus = train[\"Stemmed_Text\"].values.tolist()\n",
    "clean_test_corpus = test[\"Stemmed_Text\"].values.tolist()\n",
    "train_label = train[\"Label\"].values.tolist()\n",
    "test_label = test[\"Label\"].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Vectorizer and Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (80315, 60287)\n",
      "Testing Data (19685, 60287)\n",
      "Classifier Accuracy 86.30429260858521 %\n"
     ]
    }
   ],
   "source": [
    "# Creating Vectorizer.\n",
    "cv = CountVectorizer()\n",
    "cv.fit(clean_train_corpus)\n",
    "\n",
    "# Storing Vectorizer.\n",
    "pickle.dump(cv, open(\"sentiment_analyzer_count_vector.pickle\", \"wb\"))\n",
    "\n",
    "# Fit transform with the Training data.\n",
    "train_vctr = cv.fit_transform(clean_train_corpus)\n",
    "print(\"Training Data\", train_vctr.shape)\n",
    "\n",
    "# Transform the testing data.\n",
    "test_vctr = cv.transform(clean_test_corpus)\n",
    "print(\"Testing Data\", test_vctr.shape)\n",
    "\n",
    "# Train Classifier.\n",
    "clf = GradientBoostingClassifier(learning_rate=0.01, n_estimators=1000, max_depth=24,\n",
    "                                 min_samples_split=3, min_samples_leaf=3,\n",
    "                                 max_features='sqrt', random_state=42)\n",
    "# Train all Classifier on the training Data.\n",
    "clf.fit(train_vctr, train_label)\n",
    "\n",
    "# Storing model.\n",
    "pickle.dump(clf, open(\"sentiment_analyzer_gbm.pickle\", 'wb'))\n",
    "\n",
    "\n",
    "# Predict Test Data.\n",
    "predictions = clf.predict(test_vctr)\n",
    "\n",
    "# Accuracy.\n",
    "print(\"Classifier Accuracy\", accuracy_score(predictions, test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Runtime: 755 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTotal Runtime:\", int(time.time()-strt_time), \"seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
